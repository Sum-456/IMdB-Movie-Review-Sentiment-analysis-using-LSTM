{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOc5E7yrFXG2usq95qrHMj4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"C54a4X3LfTDd","executionInfo":{"status":"error","timestamp":1743950360467,"user_tz":-330,"elapsed":7738,"user":{"displayName":"Sumedha Pal","userId":"00300615560095726386"}},"outputId":"3b669b59-275d-40e4-99c0-eab7878319a5"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"File format not supported: filepath=/content/tokenizer.pkl. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/content/tokenizer.pkl, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-910278e23773>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/tokenizer.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/my_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;34mf\"File format not supported: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;34m\"Keras 3 only supports V3 `.keras` files and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=/content/tokenizer.pkl. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/content/tokenizer.pkl, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."]}],"source":["from keras.models import load_model\n","import joblib\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","model = load_model(\"/content/tokenizer.pkl\")\n","tokenizer = joblib.load(\"/content/my_model.h5\")\n","\n","def predict_sentiment(review):\n","  sequences = tokenizer.texts_to_sequences([review])\n","  padded_sequence = pad_sequences(sequences, maxlen=200)\n","  prediction = model.predict(padded_sequence)\n","  sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n","  return sentiment"]},{"cell_type":"code","source":["review_sentiment = predict_sentiment(\"Beautiful movie\")"],"metadata":{"id":"LqlHmTsjj15U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review_sentiment"],"metadata":{"id":"fytYIFBbkHyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"id":"ZooSWFwskKRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","title = \"MOVIE SENTIMENT ANALYSIS APPLICATION\"\n","\n","app = gr.Interface(fn = predict_sentiment, inputs=\"textbox\", outputs=\"textbox\", title=title)\n","\n","app.launch(share=True)\n"],"metadata":{"id":"hMyMXGwFkY4P"},"execution_count":null,"outputs":[]}]}